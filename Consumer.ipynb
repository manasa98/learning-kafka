{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b870d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052eb7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=healthy-lionfish-5018-us1-kafka.upstash.io:9092 <connecting> [IPv4 ('174.129.75.41', 9092)]>: connecting to healthy-lionfish-5018-us1-kafka.upstash.io:9092 [('174.129.75.41', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=healthy-lionfish-5018-us1-kafka.upstash.io:9092 <handshake> [IPv4 ('174.129.75.41', 9092)]>: Loading system default SSL CAs from DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\ssl/certs')\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=healthy-lionfish-5018-us1-kafka.upstash.io:9092 <authenticating> [IPv4 ('174.129.75.41', 9092)]>: Authenticated as aGVhbHRoeS1saW9uZmlzaC01MDE4JGxY2ft2THMMCzPDT8YMwZ08-V29NiXB6c8 via SCRAM-SHA-256\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=healthy-lionfish-5018-us1-kafka.upstash.io:9092 <authenticating> [IPv4 ('174.129.75.41', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:root:\n",
      "\n",
      "Kafka consumer initialized successfully\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    " \n",
    "consumer = KafkaConsumer( bootstrap_servers=['healthy-lionfish-5018-us1-kafka.upstash.io:9092'],\\\n",
    "                         sasl_mechanism='SCRAM-SHA-256',\\\n",
    "                         security_protocol='SASL_SSL',\\\n",
    "                         sasl_plain_username='aGVhbHRoeS1saW9uZmlzaC01MDE4JGxY2ft2THMMCzPDT8YMwZ08-V29NiXB6c8',\\\n",
    "                         sasl_plain_password='MzU1OTg2NDgtMGY1Zi00ZDU4LTkzZGYtMjUwMzViNTcyZTIx',\\\n",
    "                        value_deserializer=str,\\\n",
    "                        key_deserializer=str,\\\n",
    "                        group_id = 'my-first-kafka-python-2',\\\n",
    "                        auto_offset_reset='earliest')\n",
    "\n",
    "logging.info(\"\\n\\nKafka consumer initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b592b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ['demo_topic_latest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'demo_topic_latest'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.subscribe(['demo_topic_latest'])  #subscribe to the topic you want to consume\n",
    "consumer.subscription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a2f2af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Polling\n",
      "INFO:kafka.cluster:Group coordinator for my-first-kafka-python-2 is BrokerMetadata(nodeId='coordinator-3', host='healthy-lionfish-5018-us1-3-kafka.upstash.io', port=9095, rack=None)\n",
      "INFO:kafka.coordinator:Discovered coordinator coordinator-3 for group my-first-kafka-python-2\n",
      "INFO:kafka.coordinator:Starting new heartbeat thread\n",
      "INFO:kafka.coordinator.consumer:Revoking previously assigned partitions set() for group my-first-kafka-python-2\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <connecting> [IPv4 ('174.129.75.41', 9095)]>: connecting to healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 [('174.129.75.41', 9095) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <handshake> [IPv4 ('174.129.75.41', 9095)]>: Loading system default SSL CAs from DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\ssl/certs')\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <authenticating> [IPv4 ('174.129.75.41', 9095)]>: Authenticated as aGVhbHRoeS1saW9uZmlzaC01MDE4JGxY2ft2THMMCzPDT8YMwZ08-V29NiXB6c8 via SCRAM-SHA-256\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <authenticating> [IPv4 ('174.129.75.41', 9095)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=healthy-lionfish-5018-us1-kafka.upstash.io:9092 <connected> [IPv4 ('174.129.75.41', 9092)]>: Closing connection. \n",
      "INFO:kafka.coordinator:(Re-)joining group my-first-kafka-python-2\n",
      "INFO:kafka.coordinator:Elected group leader -- performing partition assignments using range\n",
      "INFO:kafka.conn:<BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <connecting> [IPv4 ('174.129.75.41', 9095)]>: connecting to healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 [('174.129.75.41', 9095) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <handshake> [IPv4 ('174.129.75.41', 9095)]>: Loading system default SSL CAs from DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\ssl/certs')\n",
      "INFO:kafka.coordinator:Successfully joined group my-first-kafka-python-2 with generation 25\n",
      "INFO:kafka.consumer.subscription_state:Updated partition assignment: [TopicPartition(topic='demo_topic_latest', partition=0), TopicPartition(topic='demo_topic_latest', partition=1)]\n",
      "INFO:kafka.coordinator.consumer:Setting newly assigned partitions {TopicPartition(topic='demo_topic_latest', partition=0), TopicPartition(topic='demo_topic_latest', partition=1)} for group my-first-kafka-python-2\n",
      "INFO:kafka.conn:<BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <authenticating> [IPv4 ('174.129.75.41', 9095)]>: Authenticated as aGVhbHRoeS1saW9uZmlzaC01MDE4JGxY2ft2THMMCzPDT8YMwZ08-V29NiXB6c8 via SCRAM-SHA-256\n",
      "INFO:kafka.conn:<BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <authenticating> [IPv4 ('174.129.75.41', 9095)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 <connecting> [IPv4 ('34.195.190.47', 9093)]>: connecting to healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 [('34.195.190.47', 9093) IPv4]\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 0\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 1\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 2\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 3\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 4\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 5\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 6\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 7\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 8\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 9\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 10\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 11\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 12\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 13\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 14\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 15\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 16\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 17\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 18\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 19\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 <handshake> [IPv4 ('34.195.190.47', 9093)]>: Loading system default SSL CAs from DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\ssl/certs')\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 20\n",
      "INFO:root:key: b'id_4' | partition: 0 | offset: 21\n",
      "INFO:root:key: b'id_6' | partition: 0 | offset: 22\n",
      "INFO:root:key: b'id_9' | partition: 0 | offset: 23\n",
      "INFO:root:Polling\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 <authenticating> [IPv4 ('34.195.190.47', 9093)]>: Authenticated as aGVhbHRoeS1saW9uZmlzaC01MDE4JGxY2ft2THMMCzPDT8YMwZ08-V29NiXB6c8 via SCRAM-SHA-256\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 <authenticating> [IPv4 ('34.195.190.47', 9093)]>: Connection complete.\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 0\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 1\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 2\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 3\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 4\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 5\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 6\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 7\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 8\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 9\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 10\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 11\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 12\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 13\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 14\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 15\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 16\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 17\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 18\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 19\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 20\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 21\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 22\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 23\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 24\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 25\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 26\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 27\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 28\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 29\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 30\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 31\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 32\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 33\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 34\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 35\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 36\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 37\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 38\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 39\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 40\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 41\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 42\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 43\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 44\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 45\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 46\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:key: b'id_8' | partition: 1 | offset: 48\n",
      "INFO:root:key: b'id_0' | partition: 1 | offset: 49\n",
      "INFO:root:key: b'id_1' | partition: 1 | offset: 50\n",
      "INFO:root:key: b'id_2' | partition: 1 | offset: 51\n",
      "INFO:root:key: b'id_3' | partition: 1 | offset: 52\n",
      "INFO:root:key: b'id_5' | partition: 1 | offset: 53\n",
      "INFO:root:key: b'id_7' | partition: 1 | offset: 54\n",
      "INFO:root:key: b'id_8' | partition: 1 | offset: 55\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:root:Polling\n",
      "INFO:kafka.coordinator:Stopping heartbeat thread\n",
      "INFO:kafka.coordinator:Leaving consumer group (my-first-kafka-python-2).\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <connected> [IPv4 ('174.129.75.41', 9095)]>: Closing connection. \n",
      "INFO:kafka.conn:<BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <connected> [IPv4 ('174.129.75.41', 9095)]>: Closing connection. \n",
      "ERROR:kafka.consumer.fetcher:Fetch to node 3 failed: Cancelled: <BrokerConnection node_id=3 host=healthy-lionfish-5018-us1-3-kafka.upstash.io:9095 <connected> [IPv4 ('174.129.75.41', 9095)]>\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=healthy-lionfish-5018-us1-1-kafka.upstash.io:9093 <connected> [IPv4 ('34.195.190.47', 9093)]>: Closing connection. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolling\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     records \u001b[38;5;241m=\u001b[39m records\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\kafka\\consumer\\group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\kafka\\consumer\\group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\kafka\\client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[1;34m(self, timeout_ms, future)\u001b[0m\n\u001b[0;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[0;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\kafka\\client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[0;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\selectors.py:324\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\selectors.py:315\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 315\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while(True):\n",
    "        logging.info(\"Polling\")\n",
    "\n",
    "        records = consumer.poll(timeout_ms=1000)\n",
    "        records = records.values()\n",
    "\n",
    "        for record in records:\n",
    "            for rec in record:\n",
    "                logging.info(\"key: \"+str(rec.key)+\" | \"+\"partition: \"+str(rec.partition)+\" | \"+\"offset: \"+str(rec.offset))\n",
    "finally:\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317e6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
